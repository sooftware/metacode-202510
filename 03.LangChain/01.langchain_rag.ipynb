{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a7c5f7-bcd8-41d9-b936-ecae419552bd",
   "metadata": {},
   "source": [
    "# LangChain으로 구현하는 RAG 시스템 실습\n",
    "\n",
    "이번 실습에서는 LangChain을 활용하여 완전한 RAG 시스템을 구축해봅니다.  \n",
    "회사 정보를 담은 JSON 데이터를 기반으로 질문에 답변하는 AI 챗봇을 만들어볼게요!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972497d-3425-4cde-8dee-5eb68ee57910",
   "metadata": {},
   "source": [
    "## 0. 환경설정\n",
    "\n",
    "### 필요한 라이브러리 설치\n",
    "  \n",
    "먼저 터미널에서 필요한 패키지들을 설치합니다.\n",
    "\n",
    "```\n",
    "pip install langchain langchain-openai langchain-community chromadb openai python-dotenv langsmith faiss-cpu\n",
    "```\n",
    "\n",
    "### 라이브러리 Import 및 API 키 설정\n",
    "\n",
    "\n",
    "먼저 .env 파일을 생성하여 API 키를 관리합니다:\n",
    "\n",
    "```\n",
    "# .env 파일\n",
    "OPENAI_API_KEY=sk-your-openai-api-key\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_API_KEY=ls_your-langsmith-api-key\n",
    "LANGCHAIN_PROJECT=langchain-rag-tutorial\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845875bd-a6a0-4a4f-a5f6-fe3b1ab04b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangSmith 추적 활성화!\n",
      "✅ 환경 설정 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "try:\n",
    "    from langsmith import traceable\n",
    "\n",
    "    LANGSMITH_AVAILABLE = True\n",
    "    print(\"✅ LangSmith 추적 활성화!\")\n",
    "except ImportError:\n",
    "    LANGSMITH_AVAILABLE = False\n",
    "\n",
    "# LangChain 관련\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ 환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f5db9-f3fa-478e-8e86-04e2f12298f7",
   "metadata": {},
   "source": [
    "#### 💡 **LangSmith**란?   \n",
    "\n",
    "LangSmith는 LangChain 애플리케이션의 실행을 추적하고 모니터링하는 도구입니다. 각 단계별 실행 시간, 입출력, 비용 등을 시각적으로 확인할 수 있어 디버깅과 최적화에 매우 유용합니다!    \n",
    "LangSmith API 키는 https://smith.langchain.com에서 무료로 발급받을 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606fcdc0-56e4-4e71-8b67-7f8a7a2b4154",
   "metadata": {},
   "source": [
    "## 1. 사전 준비 단계\n",
    "\n",
    "### Document Loader (문서 로드)\n",
    "  \n",
    "이 단계에서는 외부 데이터 소스에서 필요한 문서를 로드하고 초기 처리를 합니다.   \n",
    "이번 예제에서는 회자 정보를 담은 JSON 파일을 로드해서 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5a1b59-56bf-4e5b-ae10-23d1819ba833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 20개의 데이터 로드 완료!\n",
      "\n",
      "첫 번째 데이터 예시:\n",
      "{\n",
      "  \"id\": \"company_overview\",\n",
      "  \"topic\": \"회사 소개\",\n",
      "  \"content\": \"테크노바는 2020년에 설립된 AI 기반 솔루션을 제공하는 스타트업입니다. 서울 강남구에 본사를 두고 있으며, 현재 직원 수는 약 50명입니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# JSON 파일에서 데이터 로드\n",
    "with open('company_info.json', 'r', encoding='utf-8') as f:\n",
    "    company_data = json.load(f)\n",
    "\n",
    "print(f\"✅ 총 {len(company_data)}개의 데이터 로드 완료!\")\n",
    "print(f\"\\n첫 번째 데이터 예시:\")\n",
    "print(json.dumps(company_data[0], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12cd63f-a68e-452f-93ce-977e65db14a8",
   "metadata": {},
   "source": [
    "### Document 객체로 변환\n",
    "\n",
    "LangChain에서 사용할 수 있도록 데이터를 Document 형식으로 변환합니다.\n",
    "Document는 page_content(본문)와 metadata(메타데이터)로 구성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3c7b92-9bc6-4c8e-b3c8-a71f574bb574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 20개의 Document 객체 생성 완료!\n",
      "\n",
      "첫 번째 Document 예시:\n",
      "내용: Topic: 회사 소개\n",
      "Content: 테크노바는 2020년에 설립된 AI 기반 솔루션을 제공하는 스타트업입니다. 서울 강남구에 본사를 두고 있으며, 현재 직원 수는 약 50명입니다.\n",
      "메타데이터: {'id': 'company_overview', 'topic': '회사 소개'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = []\n",
    "\n",
    "for item in company_data:\n",
    "    doc = Document(\n",
    "        page_content=f\"Topic: {item['topic']}\\nContent: {item['content']}\",\n",
    "        metadata={\n",
    "            \"id\": item[\"id\"],\n",
    "            \"topic\": item[\"topic\"]\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"✅ {len(documents)}개의 Document 객체 생성 완료!\\n\")\n",
    "print(\"첫 번째 Document 예시:\")\n",
    "print(f\"내용: {documents[0].page_content}\")\n",
    "print(f\"메타데이터: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c362bed2-5ff3-48c0-8a26-be755aeb3f84",
   "metadata": {},
   "source": [
    "## 2. Text Splitting (텍스트 분할)\n",
    "\n",
    "### 왜 텍스트를 분할하나요?\n",
    "\n",
    "긴 문서를 그대로 사용하면 검색 정확도가 떨어집니다. 큰 책을 작은 챕터로 나누듯이, 문서를 적절한 크기의 청크(chunk)로 분할하면 더 정확한 검색이 가능합니다.  \n",
    "      \n",
    "예를 들어, \"회사 위치가 어디인가요?\"라는 질문에 대해 전체 문서 대신 결혼식 정보만 담긴 작은 청크를 검색할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34886d6-9122-4a09-b0fe-0ea51878ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 텍스트 분할 완료!\n",
      "원본 문서 수: 20\n",
      "분할 후 청크 수: 20\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,      # 청크 하나당 최대 200자\n",
    "    chunk_overlap=50,    # 청크 간 50자 겹침 (문맥 유지)\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"✅ 텍스트 분할 완료!\")\n",
    "print(f\"원본 문서 수: {len(documents)}\")\n",
    "print(f\"분할 후 청크 수: {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7817fe2-f3d2-4481-9012-22c64e71d854",
   "metadata": {},
   "source": [
    "💡 Tip: 이 예시에서는 문서가 짧아 분할이 크게 일어나지 않지만, 실제로 긴 문서를 다룰 때는 여러 개의 청크로 나뉩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bfaa9a-3d42-43fd-80cc-77dfe9a46729",
   "metadata": {},
   "source": [
    "## 3. Embedding (임베딩)\n",
    "\n",
    "### 임베딩이란?  \n",
    "\n",
    "임베딩은 텍스트를 숫자 벡터로 변환하는 과정입니다. 컴퓨터는 텍스트의 의미를 직접 이해할 수 없기 때문에, 수치로 표현해야 합니다.  \n",
    "비슷한 의미를 가진 텍스트는 벡터 공간에서 가까운 위치에 배치됩니다.\n",
    "\n",
    "- \"결혼식 날짜\" ≈ \"예식 일정\"\n",
    "- \"신랑 직업\" ≈ \"신랑님은 무슨 일을 하시나요\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "207b2aa7-583e-4592-9706-e2d1de8a74e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 임베딩 모델 초기화 완료!\n",
      "\n",
      "샘플 텍스트: '회사 위치가 어디인가요?'\n",
      "임베딩 벡터 차원: 1536\n",
      "임베딩 벡터 일부: [0.015228848904371262, 0.012781930156052113, 0.05640791356563568, 0.05310242623090744, 0.013790748082101345]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# 테스트: 샘플 텍스트 임베딩\n",
    "sample_text = \"회사 위치가 어디인가요?\"\n",
    "sample_embedding = embeddings.embed_query(sample_text)\n",
    "\n",
    "print(f\"✅ 임베딩 모델 초기화 완료!\")\n",
    "print(f\"\\n샘플 텍스트: '{sample_text}'\")\n",
    "print(f\"임베딩 벡터 차원: {len(sample_embedding)}\")\n",
    "print(f\"임베딩 벡터 일부: {sample_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c204b-81d0-4135-bb7b-39c9cef59ae5",
   "metadata": {},
   "source": [
    "## 4. Vector Store (벡터 저장소)\n",
    "\n",
    "### Chroma DB에 저장하기\n",
    "  \n",
    "임베딩된 벡터들을 저장하고 검색할 수 있는 데이터베이스를 만듭니다.  \n",
    "도서관의 색인 시스템과 비슷합니다. 책의 내용을 분류하고 저장해두면, 나중에 원하는 정보를 빠르게 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c178adcc-cee3-428f-85a3-4edfe2186029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chroma 벡터 스토어 생성 완료!\n",
      "저장된 문서 수: 40\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"company_info\",\n",
    "    persist_directory=\"./chroma_db\"  # 로컬에 저장\n",
    ")\n",
    "\n",
    "print(f\"✅ Chroma 벡터 스토어 생성 완료!\")\n",
    "print(f\"저장된 문서 수: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f025488-4be4-4afa-826d-58af7f48a1e4",
   "metadata": {},
   "source": [
    "💡 Chroma의 장점: 별도의 저장 명령 없이 persist_directory를 지정하면 자동으로 디스크에 저장됩니다!  \n",
    "  \n",
    "⚠️ 주의: 기존 DB가 있으면 스키마 충돌이 발생할 수 있으니, 처음 실행 시 기존 폴더를 삭제하거나 다른 collection_name을 사용하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a5e0b-de92-4bb6-b756-fe11b1af7ab1",
   "metadata": {},
   "source": [
    "## 5. Retriever (검색기)\n",
    "\n",
    "### 다양한 검색 방식 이해하기\n",
    "  \n",
    "Retriever는 질문과 가장 유사한 문서를 찾아주는 역할을 합니다.  \n",
    "FAISS에서는 여러 가지 검색 옵션을 제공합니다.\n",
    "  \n",
    "### 방법 1: 기본 유사도 검색 (Similarity Search)\n",
    "  \n",
    "가장 유사한 상위 k개의 문서를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecee0ab9-3094-4094-bd40-0904603dd26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 기본 Retriever 설정 완료!\n",
      "\n",
      "테스트 질문: '회사 팀은 어떻게 구성되어 있나요?'\n",
      "검색된 문서 수: 3\n",
      "\n",
      "가장 관련성 높은 문서:\n",
      "회사는 크게 개발팀, 디자인팀, 영업팀, 마케팅팀으로 구성되어 있습니다. 개발팀이 가장 크며 약 30명의 엔지니어가 근무하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 기본 Retriever 설정\n",
    "retriever_basic = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # 상위 3개 문서 검색\n",
    ")\n",
    "\n",
    "print(\"✅ 기본 Retriever 설정 완료!\")\n",
    "\n",
    "# 테스트\n",
    "test_query = \"회사 팀은 어떻게 구성되어 있나요?\"\n",
    "retrieved_docs = retriever_basic.invoke(test_query)\n",
    "\n",
    "print(f\"\\n테스트 질문: '{test_query}'\")\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")\n",
    "print(f\"\\n가장 관련성 높은 문서:\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c729b-0715-411a-91ca-e750625ddef7",
   "metadata": {},
   "source": [
    "### 방법 2: 유사도 점수 임계값 검색 (Similarity Score Threshold)\n",
    "  \n",
    "일정 유사도 이상인 문서만 검색합니다. 관련성이 낮은 문서를 필터링할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86af8198-57b1-434c-a39c-ec1d1c31fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 유사도 임계값 Retriever 설정 완료!\n",
      "\n",
      "테스트 질문: '회사의 주요 고객사는 어떻게 되나요?'\n",
      "유사도 0.3 이상인 문서 수: 1\n",
      "  [1] 주요 고객사\n"
     ]
    }
   ],
   "source": [
    "# 유사도 임계값 Retriever\n",
    "retriever_threshold = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.3,  # 유사도 0.3 이상만 반환\n",
    "        \"k\": 5  # 최대 5개까지\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ 유사도 임계값 Retriever 설정 완료!\")\n",
    "\n",
    "# 테스트\n",
    "test_query = \"회사의 주요 고객사는 어떻게 되나요?\"\n",
    "retrieved_docs = retriever_threshold.invoke(test_query)\n",
    "\n",
    "print(f\"\\n테스트 질문: '{test_query}'\")\n",
    "print(f\"유사도 0.3 이상인 문서 수: {len(retrieved_docs)}\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"  [{i}] {doc.metadata.get('topic', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d210567-5a3a-49f3-8df6-0b5cf206eb7a",
   "metadata": {},
   "source": [
    "### 방법 3: MMR (Maximum Marginal Relevance)\n",
    "\n",
    "유사도가 높으면서도 다양성을 보장하는 검색 방식입니다. 비슷한 내용의 문서가 중복으로 검색되는 것을 방지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "802334d5-0926-4c90-bfb4-1f2819b6176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MMR Retriever 설정 완료!\n",
      "\n",
      "테스트 질문: '회사의 주요 고객사는 어떻게 되나요?'\n",
      "MMR로 검색된 다양한 문서들:\n",
      "  [1] 주요 고객사\n",
      "  [2] 팀 구조\n",
      "  [3] 회사 문화\n",
      "  [4] 복지 제도\n"
     ]
    }
   ],
   "source": [
    "# MMR Retriever\n",
    "retriever_mmr = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 4,  # 최종적으로 4개 반환\n",
    "        \"fetch_k\": 10,  # 먼저 10개를 가져온 후\n",
    "        \"lambda_mult\": 0.5  # 다양성 조절 (0=다양성 우선, 1=유사도 우선)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ MMR Retriever 설정 완료!\")\n",
    "\n",
    "# 테스트\n",
    "test_query = \"회사의 주요 고객사는 어떻게 되나요?\"\n",
    "retrieved_docs = retriever_mmr.invoke(test_query)\n",
    "\n",
    "print(f\"\\n테스트 질문: '{test_query}'\")\n",
    "print(f\"MMR로 검색된 다양한 문서들:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"  [{i}] {doc.metadata.get('topic', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae6327-3e32-4f63-b601-a6f6c952d2b1",
   "metadata": {},
   "source": [
    "#### 💡 MMR 파라미터:\n",
    "\n",
    "- fetch_k: 후보 문서 개수 (많을수록 다양성 확보)\n",
    "- lambda_mult: 0.5가 균형잡힌 값 (유사도와 다양성의 균형)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28a809-e51b-44da-afaa-7ba55ec51658",
   "metadata": {},
   "source": [
    "### 검색 방식 비교 및 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21e27fa6-f25f-4ec4-8e33-000987515ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: '대표이사는 누구인가요?'\n",
      "검색 결과 (유사도 점수 포함):\n",
      "\n",
      "주제: 대표이사\n",
      "유사도 점수: 1.3875\n",
      "내용: Topic: 대표이사\n",
      "Content: 김철수 대표는 카이스트에서 인공지능을 전공했으며, 이전에 네이버에서 A...\n",
      "\n",
      "주제: 대표이사\n",
      "유사도 점수: 1.5376\n",
      "내용: 김철수 대표는 카이스트에서 인공지능을 전공했으며, 이전에 네이버에서 AI 연구원으로 근무했습니다. 10년 이...\n",
      "\n",
      "주제: 사무실 위치\n",
      "유사도 점수: 1.6260\n",
      "내용: 본사는 서울특별시 강남구 테헤란로 123에 위치해 있습니다. 지하철 2호선 강남역에서 도보 5분 거리이며, ...\n"
     ]
    }
   ],
   "source": [
    "# 직접 유사도 점수 확인하기\n",
    "test_query = \"대표이사는 누구인가요?\"\n",
    "docs_with_scores = vectorstore.similarity_search_with_score(test_query, k=3)\n",
    "\n",
    "print(f\"\\n질문: '{test_query}'\")\n",
    "print(\"검색 결과 (유사도 점수 포함):\")\n",
    "for doc, score in docs_with_scores:\n",
    "    print(f\"\\n주제: {doc.metadata.get('topic', 'N/A')}\")\n",
    "    print(f\"유사도 점수: {score:.4f}\")\n",
    "    print(f\"내용: {doc.page_content[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088d25c-a0a4-41cf-884d-e51e0935a053",
   "metadata": {},
   "source": [
    "#### 이번 실습에서는 기본 유사도 검색을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51d2b835-a5de-49e8-9651-818f1feeb433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 실습용 Retriever 설정 완료!\n"
     ]
    }
   ],
   "source": [
    "# 실습용 Retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "print(\"✅ 실습용 Retriever 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cce539-26d8-43ca-8f33-87b472bfffd9",
   "metadata": {},
   "source": [
    "## 6. LLM 초기화 및 프롬프트 작성\n",
    "\n",
    "### ChatGPT 모델 설정  \n",
    "  \n",
    "검색된 문서를 바탕으로 자연스러운 답변을 생성할 LLM을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fa47242-62bf-4009-be9d-4998c94eab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM 모델 초기화 완료!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"✅ LLM 모델 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b621f3-5607-4c00-8031-d440087e2d22",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿 작성\n",
    "  \n",
    "RAG 시스템이 어떻게 답변할지 가이드를 제공하는 프롬프트 템플릿을 작성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d677b6c1-3c7d-448d-b1d0-143007ad696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 프롬프트 템플릿 작성 완료!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "당신은 결혼식 정보를 안내하는 친절한 AI 어시스턴트입니다.\n",
    "제공된 컨텍스트를 기반으로 질문에 답변해주세요.\n",
    "컨텍스트에 정보가 없다면 \"죄송하지만 해당 정보는 제공되지 않았습니다\"라고 답변하세요.\n",
    "답변은 친근하고 따뜻한 톤으로 작성해주세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\n",
    "\"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"✅ 프롬프트 템플릿 작성 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05c8d0-cda2-4294-b221-5ff8970e0a37",
   "metadata": {},
   "source": [
    "## 7. RAG Chain 구성\n",
    "\n",
    "### LCEL(LangChain Expression Language)로 체인 만들기\n",
    "\n",
    "이제 파이프(|) 연산자를 사용하여 RAG 체인을 만들어봅시다.  \n",
    "파이프 연산자는 데이터가 흐르는 방향을 명확하게 보여줍니다. 마치 공장의 컨베이어 벨트처럼 각 단계를 거쳐 최종 결과물이 만들어집니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34692633-7a5e-408e-aa31-be309a357952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG 체인 구성 완료!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever,  # 질문과 관련된 문서 검색\n",
    "        \"question\": RunnablePassthrough()  # 질문을 그대로 전달\n",
    "    }\n",
    "    | PROMPT  # 프롬프트 템플릿에 context와 question 삽입\n",
    "    | llm  # LLM이 답변 생성\n",
    "    | StrOutputParser()  # 문자열로 파싱\n",
    ")\n",
    "\n",
    "print(\"✅ RAG 체인 구성 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e2283-381c-4256-befb-d83acb1b1b3c",
   "metadata": {},
   "source": [
    "### 데이터 흐름 이해하기:\n",
    "\n",
    "```\n",
    "사용자 질문\n",
    "    ↓\n",
    "① {\"context\": 검색된 문서들, \"question\": 원본 질문}\n",
    "    ↓\n",
    "② PROMPT (프롬프트에 context와 question이 들어감)\n",
    "    ↓\n",
    "③ LLM (답변 생성)\n",
    "    ↓\n",
    "④ StrOutputParser (문자열로 변환)\n",
    "    ↓\n",
    "최종 답변\n",
    "```\n",
    "\n",
    "\n",
    "💡 LCEL이란? LangChain Expression Language의 약자로, | 연산자로 각 단계를 연결하는 직관적인 방식입니다. 각 컴포넌트가 순서대로 실행되며, 앞 단계의 출력이 다음 단계의 입력으로 자동으로 전달됩니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbae31-30a8-4ee3-a9a5-fc077f271fb6",
   "metadata": {},
   "source": [
    "### Invoke 메서드로 체인 실행하기\n",
    "  \n",
    "체인을 실행하는 방법은 여러 가지가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb942c-46ba-458a-986d-66049742a31c",
   "metadata": {},
   "source": [
    "### 방법 1: invoke() - 단일 실행  \n",
    "  \n",
    "가장 기본적인 실행 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b57e81c4-20bf-4c44-9c3f-ed7716542fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 회사는 언제 설립되었나요?\n",
      "답변: 테크노바는 2020년에 설립되었습니다! 궁금한 점이 더 있으시면 언제든지 말씀해 주세요.\n"
     ]
    }
   ],
   "source": [
    "# 단일 질문 실행\n",
    "question = \"회사는 언제 설립되었나요?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"질문: {question}\")\n",
    "print(f\"답변: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224991c-62aa-4e0c-9571-95220e9b0625",
   "metadata": {},
   "source": [
    "### 방법 2: batch() - 여러 질문 동시 실행\n",
    "  \n",
    "여러 질문을 한 번에 처리할 때 효율적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d54042d-4da8-410b-9564-ad9def1bbbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: 주력 제품은 무엇인가요?\n",
      "A: 우리의 주력 제품은 'SmartAssist'라는 AI 챗봇 플랫폼입니다. 이 플랫폼은 고객 서비스 자동화와 업무 효율성 향상을 위한 훌륭한 솔루션을 제공합니다. 더 궁금한 점이 있으시면 언제든지 말씀해 주세요!\n",
      "\n",
      "Q: 사무실은 어디에 있나요?\n",
      "A: 안녕하세요! 저희 사무실은 서울특별시 강남구 테헤란로 123에 위치해 있습니다. 지하철 2호선 강남역에서 도보로 약 5분 거리에 있으며, 15층에 있습니다. 언제든지 방문해 주세요! 😊\n",
      "\n",
      "Q: 근무 시간은 어떻게 되나요?\n",
      "A: 안녕하세요! 근무 시간은 오전 9시부터 오후 6시까지이며, 코어타임은 오전 10시부터 오후 4시까지입니다. 주 5일 근무제를 시행하고 있어요. 궁금한 점이 더 있으면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 여러 질문 동시 실행\n",
    "questions = [\n",
    "    \"주력 제품은 무엇인가요?\",\n",
    "    \"사무실은 어디에 있나요?\",\n",
    "    \"근무 시간은 어떻게 되나요?\"\n",
    "]\n",
    "\n",
    "answers = rag_chain.batch(questions)\n",
    "\n",
    "for q, a in zip(questions, answers):\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188b48e-0a40-427d-8258-9cda97f65206",
   "metadata": {},
   "source": [
    "### 방법 3: stream() - 스트리밍 응답\n",
    "\n",
    "답변이 생성되는 과정을 실시간으로 볼 수 있습니다. ChatGPT처럼 글자가 하나씩 나타나는 효과를 만들 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d1066fd-1fb2-4de6-a791-918ab314ba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 회사의 복지 제도는 어떤가요?\n",
      "답변: 회사의 복지 제도는 정말 훌륭해요! 직원들에게 최신형 맥북 프로와 듀얼 모니터를 제공하고, 점심 식대를 지원하며 간식도 무제한으로 제공된답니다. 또한, 연 1회 워크샵과 도서 구입비 지원도 있어 직원들이 더욱 성장할 수 있도록 도와주고 있어요. 정말 든든한 지원이죠!\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍 실행\n",
    "question = \"회사의 복지 제도는 어떤가요?\"\n",
    "print(f\"질문: {question}\")\n",
    "print(\"답변: \", end=\"\")\n",
    "\n",
    "for chunk in rag_chain.stream(question):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e685be5-4a94-4098-8e68-04accf171d1e",
   "metadata": {},
   "source": [
    "## 8. RAG 시스템 테스트\n",
    "\n",
    "### 질문 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21df4258-7862-43af-9427-027b7188da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    \"\"\"질문에 대한 답변과 출처를 출력하는 함수\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"❓ 질문: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 답변 생성\n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    # 검색된 문서 확인 (별도로 retriever 호출)\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    print(f\"\\n💬 답변:\\n{answer}\")\n",
    "    print(f\"\\n📚 참고한 문서:\")\n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"\\n  [{i}] {doc.metadata.get('topic', 'N/A')}\")\n",
    "        print(f\"      {doc.page_content[:80]}...\")\n",
    "    \n",
    "    return answer, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c34dba-81d7-45cf-8258-ed23c1ee2958",
   "metadata": {},
   "source": [
    "### 스트리밍 질문 함수 만들기\n",
    "  \n",
    "실시간으로 답변이 생성되는 것을 볼 수 있는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94bf0a96-229c-4d87-a8da-ded4d797e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_stream(question):\n",
    "    \"\"\"스트리밍 방식으로 답변을 출력하는 함수\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"❓ 질문: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n💬 답변: \", end=\"\", flush=True)\n",
    "    \n",
    "    # 스트리밍 답변 생성\n",
    "    for chunk in rag_chain.stream(question):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bfab89-63f5-4efe-a246-9b72551993c1",
   "metadata": {},
   "source": [
    "### 다양한 질문으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "714e2a9f-7718-4592-b1f1-fb5895514457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "❓ 질문: 회사 팀 구조는 어떻게 되나요?\n",
      "============================================================\n",
      "\n",
      "💬 답변:\n",
      "회사의 팀 구조는 크게 개발팀, 디자인팀, 영업팀, 마케팅팀으로 구성되어 있어요. 그중에서도 개발팀이 가장 크며, 약 30명의 엔지니어가 함께 일하고 있답니다. 도움이 더 필요하시면 언제든지 말씀해 주세요!\n",
      "\n",
      "📚 참고한 문서:\n",
      "\n",
      "  [1] 팀 구조\n",
      "      회사는 크게 개발팀, 디자인팀, 영업팀, 마케팅팀으로 구성되어 있습니다. 개발팀이 가장 크며 약 30명의 엔지니어가 근무하고 있습니다....\n",
      "\n",
      "  [2] 팀 구조\n",
      "      Topic: 팀 구조\n",
      "Content: 회사는 크게 개발팀, 디자인팀, 영업팀, 마케팅팀으로 구성되어 있습니다. 개발팀이 가장 크며 약 30명의 ...\n",
      "\n",
      "  [3] 회사 소개\n",
      "      Topic: 회사 소개\n",
      "Content: 테크노바는 2020년에 설립된 AI 기반 솔루션을 제공하는 스타트업입니다. 서울 강남구에 본사를 두고 있...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('회사의 팀 구조는 크게 개발팀, 디자인팀, 영업팀, 마케팅팀으로 구성되어 있어요. 그중에서도 개발팀이 가장 크며, 약 30명의 엔지니어가 함께 일하고 있답니다. 도움이 더 필요하시면 언제든지 말씀해 주세요!',\n",
       " [Document(metadata={'id': 'team_structure', 'topic': '팀 구조'}, page_content='회사는 크게 개발팀, 디자인팀, 영업팀, 마케팅팀으로 구성되어 있습니다. 개발팀이 가장 크며 약 30명의 엔지니어가 근무하고 있습니다.'),\n",
       "  Document(metadata={'id': 'team_structure', 'topic': '팀 구조'}, page_content='Topic: 팀 구조\\nContent: 회사는 크게 개발팀, 디자인팀, 영업팀, 마케팅팀으로 구성되어 있습니다. 개발팀이 가장 크며 약 30명의 엔지니어가 근무하고 있습니다.'),\n",
       "  Document(metadata={'id': 'company_overview', 'topic': '회사 소개'}, page_content='Topic: 회사 소개\\nContent: 테크노바는 2020년에 설립된 AI 기반 솔루션을 제공하는 스타트업입니다. 서울 강남구에 본사를 두고 있으며, 현재 직원 수는 약 50명입니다.')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 1: 회사 소개\n",
    "ask_question(\"회사 팀 구조는 어떻게 되나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "268d8de1-3be0-4378-b635-e613f2c9013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "❓ 질문: 투자는 얼마나 받았나요?\n",
      "============================================================\n",
      "\n",
      "💬 답변:\n",
      "2023년에 시리즈 A 라운드에서 50억원의 투자를 유치했습니다! 정말 멋진 성과네요!\n",
      "\n",
      "📚 참고한 문서:\n",
      "\n",
      "  [1] 투자 유치\n",
      "      Topic: 투자 유치\n",
      "Content: 2023년에 시리즈 A 라운드에서 50억원의 투자를 유치했습니다. 주요 투자사는 카카오벤처스와 네이버 D...\n",
      "\n",
      "  [2] 투자 유치\n",
      "      2023년에 시리즈 A 라운드에서 50억원의 투자를 유치했습니다. 주요 투자사는 카카오벤처스와 네이버 D2SF입니다....\n",
      "\n",
      "  [3] 성장 현황\n",
      "      설립 이후 매년 100% 이상의 성장률을 기록하고 있으며, 2024년 목표 매출은 100억원입니다. 해외 진출도 계획하고 있습니다....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2023년에 시리즈 A 라운드에서 50억원의 투자를 유치했습니다! 정말 멋진 성과네요!',\n",
       " [Document(metadata={'id': 'funding', 'topic': '투자 유치'}, page_content='Topic: 투자 유치\\nContent: 2023년에 시리즈 A 라운드에서 50억원의 투자를 유치했습니다. 주요 투자사는 카카오벤처스와 네이버 D2SF입니다.'),\n",
       "  Document(metadata={'id': 'funding', 'topic': '투자 유치'}, page_content='2023년에 시리즈 A 라운드에서 50억원의 투자를 유치했습니다. 주요 투자사는 카카오벤처스와 네이버 D2SF입니다.'),\n",
       "  Document(metadata={'id': 'growth', 'topic': '성장 현황'}, page_content='설립 이후 매년 100% 이상의 성장률을 기록하고 있으며, 2024년 목표 매출은 100억원입니다. 해외 진출도 계획하고 있습니다.')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 2: 데이터에 있는 정보\n",
    "ask_question(\"투자는 얼마나 받았나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052acdc8-9344-4df7-ac34-2e1576c8bf09",
   "metadata": {},
   "source": [
    "## 인터랙티브 채팅\n",
    "\n",
    "### 대화형 인터페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89968ecb-6024-4b99-8fa4-654bbcca6ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🤖 RAG 챗봇이 준비되었습니다!\n",
      "질문을 입력하세요. (종료하려면 'quit' 입력)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "질문:  최근 성장 현황이 어떤가요?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 답변: 안녕하세요! 최근 성장 현황에 대해 알려드릴게요. 설립 이후 매년 100% 이상의 성장률을 기록하고 있으며, 2024년 목표 매출은 100억원으로 설정되어 있습니다. 또한 해외 진출도 계획하고 있다는 긍정적인 소식이 있습니다. 더 궁금한 점이 있으시면 언제든지 말씀해 주세요!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "질문:  투자쪽은 어때요?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 답변: 안녕하세요! 투자 쪽에 대한 정보가 있어요. 2023년에 시리즈 A 라운드에서 50억원의 투자를 유치했답니다. 주요 투자사로는 카카오벤처스와 네이버 D2SF가 있죠. 더 궁금한 점이 있으시면 언제든지 물어보세요! 😊\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "질문:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "챗봇을 종료합니다. 감사합니다! 👋\n"
     ]
    }
   ],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"사용자와 대화하는 인터랙티브 모드\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🤖 RAG 챗봇이 준비되었습니다!\")\n",
    "    print(\"질문을 입력하세요. (종료하려면 'quit' 입력)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_question = input(\"\\n질문: \")\n",
    "        \n",
    "        if user_question.lower() in ['quit', 'exit', 'q', '종료']:\n",
    "            print(\"\\n챗봇을 종료합니다. 감사합니다! 👋\")\n",
    "            break\n",
    "        \n",
    "        if not user_question.strip():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            answer = rag_chain.invoke(user_question)\n",
    "            print(f\"\\n🤖 답변: {answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 오류 발생: {str(e)}\")\n",
    "\n",
    "# 실행\n",
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4ef1b-83e1-46eb-a5c4-10d1b1d59f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
