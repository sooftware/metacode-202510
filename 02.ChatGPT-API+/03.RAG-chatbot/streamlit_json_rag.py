import streamlit as st
import json
import openai
import numpy as np
from typing import List, Dict, Any
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê°œì¸ ì •ë³´ RAG ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'rag_system' not in st.session_state:
    st.session_state.rag_system = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False


class StreamlitRAG:
    def __init__(self):
        self.documents = []
        self.embeddings = []
        self.metadata = []

    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            response = openai.embeddings.create(
                model="text-embedding-ada-002",
                input=text.replace("\n", " ")
            )
            return response.data[0].embedding
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return []

    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not vec1 or not vec2:
            return 0
        vec1, vec2 = np.array(vec1), np.array(vec2)
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

    def load_json_data(self, json_data: dict) -> bool:
        """JSON ë°ì´í„°ì—ì„œ ì„ë² ë”© ìƒì„±"""
        try:
            self.documents.clear()
            self.embeddings.clear()
            self.metadata.clear()

            progress_bar = st.progress(0)
            status_text = st.empty()

            total_items = sum(len(items) for items in json_data.values() if isinstance(items, list))
            current_item = 0

            for category, items in json_data.items():
                if isinstance(items, list):
                    for item in items:
                        status_text.text(f"ì²˜ë¦¬ ì¤‘: {item.get('title', 'Unknown')}")

                        # í…ìŠ¤íŠ¸ ê²°í•©
                        text = f"{item.get('title', '')}\n{item.get('content', '')}"

                        # ì„ë² ë”© ìƒì„±
                        embedding = self.get_embedding(text)
                        if embedding:
                            self.documents.append(text)
                            self.embeddings.append(embedding)
                            self.metadata.append({
                                'category': category,
                                'title': item.get('title', 'Unknown'),
                                'id': item.get('id', f"{category}_{len(self.documents)}")
                            })

                        current_item += 1
                        progress_bar.progress(current_item / total_items)

            progress_bar.empty()
            status_text.empty()
            return True

        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
            return False

    def search(self, query: str, top_k: int = 2) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.embeddings:
            return []

        query_embedding = self.get_embedding(query)
        if not query_embedding:
            return []

        results = []
        for i, doc_embedding in enumerate(self.embeddings):
            similarity = self.cosine_similarity(query_embedding, doc_embedding)
            results.append({
                'document': self.documents[i],
                'similarity': similarity,
                'metadata': self.metadata[i]
            })

        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:top_k]

    def generate_answer(self, question: str, search_results: List[Dict]) -> str:
        """RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        context = "\n\n".join([result['document'] for result in search_results])

        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

        try:
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


def main():
    st.title("ğŸ¤– ê°œì¸ ì •ë³´ RAG ì±—ë´‡")
    st.markdown("JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ê°œì¸ ë§ì¶¤í˜• AI ì±—ë´‡ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!")
    st.markdown("---")

    # ì‚¬ì´ë“œë°” - ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # API í‚¤ ì…ë ¥
        api_key = st.text_input("OpenAI API Key", type="password")
        if api_key:
            openai.api_key = api_key

        st.markdown("---")

        # JSON íŒŒì¼ ë¡œë“œ
        st.header("ğŸ“ JSON íŒŒì¼ ë¡œë“œ")

        json_data = None
        try:
            with open('info.json', 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            st.success("âœ… info.json íŒŒì¼ ë¡œë“œ ì„±ê³µ")

            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            total_items = sum(len(items) for items in json_data.values() if isinstance(items, list))
            st.info(f"ì´ {len(json_data)}ê°œ ì¹´í…Œê³ ë¦¬, {total_items}ê°œ í•­ëª©")

            for category, items in json_data.items():
                if isinstance(items, list):
                    st.write(f"**{category}**: {len(items)}ê°œ í•­ëª©")

        except FileNotFoundError:
            st.error("âŒ info.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë™ì¼í•œ í´ë”ì— info.json íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            json_data = None
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            json_data = None

        # ë°ì´í„° ë¡œë“œ ë²„íŠ¼
        if st.button("ğŸš€ ë°ì´í„° ë¡œë“œ", type="primary"):
            if not api_key:
                st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
            elif json_data:
                with st.spinner("ë°ì´í„° ì²˜ë¦¬ ì¤‘..."):
                    if st.session_state.rag_system is None:
                        st.session_state.rag_system = StreamlitRAG()

                    success = st.session_state.rag_system.load_json_data(json_data)
                    if success:
                        st.session_state.data_loaded = True
                        st.success(f"âœ… {len(st.session_state.rag_system.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ!")
                        st.rerun()
            else:
                st.error("JSON íŒŒì¼(info.json)ì„ ìƒì„±í•´ì£¼ì„¸ìš”")

        # ìƒíƒœ í‘œì‹œ
        if st.session_state.data_loaded:
            st.success("ğŸŸ¢ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
            if st.session_state.rag_system:
                st.info(f"ğŸ“Š ë¡œë“œëœ ë¬¸ì„œ: {len(st.session_state.rag_system.documents)}ê°œ")
        else:
            st.warning("ğŸŸ¡ info.json íŒŒì¼ì„ ìƒì„±í•˜ê³  ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”")

        # ì±„íŒ… ì´ˆê¸°í™”
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.chat_history = []
            st.rerun()

    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("ğŸ’¬ ëŒ€í™”")

        if st.session_state.data_loaded and api_key:
            # ì‚¬ìš©ì ì…ë ¥
            user_question = st.text_input(
                "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
                placeholder="ì˜ˆ: ë‚´ ì·¨ë¯¸ê°€ ë­ì•¼?, ì§ì¥ì€ ì–´ë””ì•¼?, ëª©í‘œê°€ ë­ì•¼?",
                key="user_input"
            )

            # ì§ˆë¬¸ ì²˜ë¦¬
            if user_question:
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    # ê²€ìƒ‰
                    search_results = st.session_state.rag_system.search(user_question)

                    # ë‹µë³€ ìƒì„±
                    answer = st.session_state.rag_system.generate_answer(user_question, search_results)

                    # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                    st.session_state.chat_history.append({
                        'question': user_question,
                        'answer': answer,
                        'search_results': search_results
                    })

                st.rerun()

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
            for i, chat in enumerate(reversed(st.session_state.chat_history)):
                with st.expander(f"ğŸ’­ {chat['question']}", expanded=(i == 0)):
                    st.markdown(f"**ğŸ¤– ë‹µë³€:**")
                    st.markdown(chat['answer'])

                    if chat['search_results']:
                        st.markdown("**ğŸ” ì°¸ì¡° ì •ë³´:**")
                        for j, result in enumerate(chat['search_results'], 1):
                            st.markdown(f"""
                            **{j}. {result['metadata']['title']}** 
                            (ì¹´í…Œê³ ë¦¬: {result['metadata']['category']}, ìœ ì‚¬ë„: {result['similarity']:.2f})

                            {result['document'][:200]}...
                            """)

        else:
            st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ê³  info.json íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")

    with col2:
        st.header("ğŸ“Š ì •ë³´")

        if st.session_state.data_loaded and st.session_state.rag_system:
            # ë°ì´í„° í†µê³„
            categories = {}
            for meta in st.session_state.rag_system.metadata:
                cat = meta['category']
                categories[cat] = categories.get(cat, 0) + 1

            st.subheader("ğŸ“ˆ ë°ì´í„° í†µê³„")
            for category, count in categories.items():
                st.metric(category, f"{count}ê°œ")

            # ìµœê·¼ ëŒ€í™” ë¶„ì„
            if st.session_state.chat_history:
                st.subheader("ğŸ” ìµœê·¼ ê²€ìƒ‰")
                recent_chat = st.session_state.chat_history[-1]
                if recent_chat['search_results']:
                    for result in recent_chat['search_results']:
                        st.progress(
                            result['similarity'],
                            text=f"{result['metadata']['title']} ({result['similarity']:.2f})"
                        )

        # JSON êµ¬ì¡° ê°€ì´ë“œ
        st.subheader("ğŸ’¡ JSON êµ¬ì¡° ê°€ì´ë“œ")
        st.markdown("""
        ```json
        {
          "ì¹´í…Œê³ ë¦¬1": [
            {
              "id": "unique_id",
              "title": "ì œëª©",
              "content": "ë‚´ìš©"
            }
          ]
        }
        ```
        """)

        # ì‚¬ìš©ë²• ì•ˆë‚´
        st.subheader("ğŸ“– ì‚¬ìš©ë²•")
        st.markdown("""
        1. **API í‚¤ ì…ë ¥**: OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
        2. **info.json íŒŒì¼ ìƒì„±**: ì˜ˆì‹œ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì—¬ info.json íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”
        3. **ë°ì´í„° ë¡œë“œ**: 'ë°ì´í„° ë¡œë“œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        4. **ì§ˆë¬¸í•˜ê¸°**: ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”

        **ì§ˆë¬¸ ì˜ˆì‹œ:**
        - ë‚´ ì´ë¦„ì´ ë­ì•¼?
        - ì–´ë–¤ íšŒì‚¬ì—ì„œ ì¼í•´?
        - ì·¨ë¯¸ê°€ ë­ì•¼?
        - ëª©í‘œê°€ ë­ì•¼?
        """)


if __name__ == "__main__":
    main()