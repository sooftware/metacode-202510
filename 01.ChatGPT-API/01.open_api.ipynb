{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# OpenAI API ì‹¤ìŠµ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” OpenAI API ì‚¬ìš©ì„ ìœ„í•œ í™˜ê²½ ì„¤ì •ë¶€í„° ì‹¤ì „ í™œìš©ê¹Œì§€ ëª¨ë“  ê²ƒì„ ë‹¤ë£¹ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. í™˜ê²½ ì„¤ì •\n",
    "2. Tiktokenìœ¼ë¡œ í† í° ì´í•´í•˜ê¸°\n",
    "3. ê¸°ë³¸ Chat Completions API\n",
    "4. Streaming API\n",
    "5. Embedding API\n",
    "6. ëª¨ë¸ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ\n",
    "7. ì‹¤ì „ íŒ (ì—ëŸ¬ ì²˜ë¦¬, ë¹„ìš© ê´€ë¦¬)\n",
    "8. ë¯¸ë‹ˆ í”„ë¡œì íŠ¸: ê°„ë‹¨í•œ ì±—ë´‡ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 1.1 Anaconda ì„¤ì¹˜ (ì²˜ìŒ ì‹œì‘í•˜ëŠ” ê²½ìš°)\n",
    "\n",
    "**Windows/Mac/Linux ê³µí†µ:**\n",
    "1. [Anaconda ê³µì‹ ì‚¬ì´íŠ¸](https://www.anaconda.com/download) ì ‘ì†\n",
    "2. ìš´ì˜ì²´ì œì— ë§ëŠ” ì„¤ì¹˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "3. ì„¤ì¹˜ ì§„í–‰ (ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì§„í–‰)\n",
    "\n",
    "### 1.2 ê°€ìƒí™˜ê²½ ìƒì„±\n",
    "\n",
    "í„°ë¯¸ë„(Anaconda Prompt)ì—ì„œ ì‹¤í–‰:\n",
    "```bash\n",
    "# ê°€ìƒí™˜ê²½ ìƒì„±\n",
    "conda create -n openai_env python=3.10 -y\n",
    "\n",
    "# ê°€ìƒí™˜ê²½ í™œì„±í™”\n",
    "conda activate openai_env\n",
    "\n",
    "# ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì„¤ì¹˜\n",
    "conda install jupyter -y\n",
    "```\n",
    "\n",
    "### 1.3 í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "\n",
    "```bash\n",
    "# OpenAI ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "pip install openai>=1.55.0\n",
    "\n",
    "# í† í° ì¹´ìš´íŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "pip install tiktoken\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬\n",
    "pip install python-dotenv\n",
    "\n",
    "# ì›¹ ë°ëª¨ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "pip install streamlit\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬ (ì˜µì…˜)\n",
    "pip install numpy pandas\n",
    "```\n",
    "\n",
    "### 1.4 API í‚¤ ì„¤ì •\n",
    "\n",
    "1. [OpenAI Platform](https://platform.openai.com/api-keys)ì—ì„œ API í‚¤ ë°œê¸‰\n",
    "2. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ ìƒì„±\n",
    "3. ë‹¤ìŒ ë‚´ìš© ì…ë ¥:\n",
    "```\n",
    "OPENAI_API_KEY=sk-proj-your-api-key-here\n",
    "```\n",
    "\n",
    "âš ï¸ **ì¤‘ìš”:** `.env` íŒŒì¼ì€ ì ˆëŒ€ Gitì— ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”! `.gitignore`ì— ì¶”ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ë²„ì „: 3.10.18 (main, Jun  5 2025, 08:37:47) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ í™•ì¸\n",
    "import sys\n",
    "print(f\"Python ë²„ì „: {sys.version}\")\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env-load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API í‚¤ ë¡œë“œ ì™„ë£Œ: sk-pr...\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# API í‚¤ í™•ì¸ (ì• 5ìë¦¬ë§Œ í‘œì‹œ)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(f\"âœ… API í‚¤ ë¡œë“œ ì™„ë£Œ: {api_key[:5]}...\")\n",
    "else:\n",
    "    print(\"âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiktoken-header",
   "metadata": {},
   "source": [
    "## 2. Tiktokenìœ¼ë¡œ í† í° ì´í•´í•˜ê¸°\n",
    "\n",
    "í† í°ì€ OpenAI APIì˜ ê¸°ë³¸ ë‹¨ìœ„ì…ë‹ˆë‹¤. API ì‚¬ìš©ë£ŒëŠ” í† í° ìˆ˜ë¡œ ê³„ì‚°ë˜ë¯€ë¡œ ì´í•´ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤!\n",
    "\n",
    "### í† í°ì´ë€?\n",
    "- í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„\n",
    "- í•œêµ­ì–´: ëŒ€ëµ 1ê¸€ì â‰ˆ 1-2 í† í°\n",
    "- ì˜ì–´: ëŒ€ëµ 1ë‹¨ì–´ â‰ˆ 1-2 í† í°\n",
    "- ê³µë°±, ë¬¸ì¥ë¶€í˜¸ë„ í† í°ìœ¼ë¡œ ì¹´ìš´íŠ¸ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tiktoken-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”! OpenAI APIë¥¼ ë°°ì›Œë³´ìêµ¬ìš”!\n",
      "í† í° ìˆ˜: 14\n",
      "í† í° ID: [14307, 171731, 0, 7788, 17527, 10328, 4831, 33628, 33771, 8122, 5947, 10997, 7952, 0]\n",
      "\n",
      "ê° í† í° ë¶„í•´:\n",
      "  14307 -> 'ì•ˆ'\n",
      "  171731 -> 'ë…•í•˜ì„¸ìš”'\n",
      "  0 -> '!'\n",
      "  7788 -> ' Open'\n",
      "  17527 -> 'AI'\n",
      "  10328 -> ' API'\n",
      "  4831 -> 'ë¥¼'\n",
      "  33628 -> ' ë°°'\n",
      "  33771 -> 'ì›Œ'\n",
      "  8122 -> 'ë³´'\n",
      "  5947 -> 'ì'\n",
      "  10997 -> 'êµ¬'\n",
      "  7952 -> 'ìš”'\n",
      "  0 -> '!'\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# GPT-4/GPT-3.5 ëª¨ë¸ì˜ ì¸ì½”ë” ë¡œë“œ\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë¶„í•´\n",
    "text = \"ì•ˆë…•í•˜ì„¸ìš”! OpenAI APIë¥¼ ë°°ì›Œë³´ìêµ¬ìš”!\"\n",
    "tokens = encoding.encode(text)\n",
    "\n",
    "print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "print(f\"í† í° ìˆ˜: {len(tokens)}\")\n",
    "print(f\"í† í° ID: {tokens}\")\n",
    "print(f\"\\nê° í† í° ë¶„í•´:\")\n",
    "for token in tokens:\n",
    "    print(f\"  {token} -> '{encoding.decode([token])}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tiktoken-compare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "í•œêµ­ì–´:\n",
      "  í…ìŠ¤íŠ¸: ì¸ê³µì§€ëŠ¥ì€ ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
      "  ê¸€ì ìˆ˜: 19\n",
      "  í† í° ìˆ˜: 11\n",
      "  í† í°/ê¸€ì ë¹„ìœ¨: 0.58\n",
      "------------------------------------------------------------\n",
      "ì˜ì–´:\n",
      "  í…ìŠ¤íŠ¸: Artificial intelligence is a key technology of the future.\n",
      "  ê¸€ì ìˆ˜: 58\n",
      "  í† í° ìˆ˜: 10\n",
      "  í† í°/ê¸€ì ë¹„ìœ¨: 0.17\n",
      "------------------------------------------------------------\n",
      "ì½”ë“œ:\n",
      "  í…ìŠ¤íŠ¸: def hello_world():\n",
      "    print('Hello, World!')\n",
      "  ê¸€ì ìˆ˜: 45\n",
      "  í† í° ìˆ˜: 12\n",
      "  í† í°/ê¸€ì ë¹„ìœ¨: 0.27\n",
      "------------------------------------------------------------\n",
      "ì´ëª¨ì§€:\n",
      "  í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ğŸŒŸ\n",
      "  ê¸€ì ìˆ˜: 21\n",
      "  í† í° ìˆ˜: 11\n",
      "  í† í°/ê¸€ì ë¹„ìœ¨: 0.52\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# í•œêµ­ì–´ vs ì˜ì–´ í† í° ë¹„êµ\n",
    "texts = {\n",
    "    \"í•œêµ­ì–´\": \"ì¸ê³µì§€ëŠ¥ì€ ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n",
    "    \"ì˜ì–´\": \"Artificial intelligence is a key technology of the future.\",\n",
    "    \"ì½”ë“œ\": \"def hello_world():\\n    print('Hello, World!')\",\n",
    "    \"ì´ëª¨ì§€\": \"ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ğŸŒŸ\"\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "for lang, text in texts.items():\n",
    "    tokens = encoding.encode(text)\n",
    "    print(f\"{lang}:\")\n",
    "    print(f\"  í…ìŠ¤íŠ¸: {text}\")\n",
    "    print(f\"  ê¸€ì ìˆ˜: {len(text)}\")\n",
    "    print(f\"  í† í° ìˆ˜: {len(tokens)}\")\n",
    "    print(f\"  í† í°/ê¸€ì ë¹„ìœ¨: {len(tokens)/len(text):.2f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tiktoken-cost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ìŠ¤íŠ¸ ê¸¸ì´: 149 ê¸€ì\n",
      "í† í° ìˆ˜: 75\n",
      "ì˜ˆìƒ ë¹„ìš©: $0.000011 (ì•½ 0.0146ì›)\n",
      "\n",
      "ğŸ’¡ 1ë§Œ ê¸€ì ì²˜ë¦¬ ì‹œ ì˜ˆìƒ ë¹„ìš©: ì•½ 0.98ì›\n"
     ]
    }
   ],
   "source": [
    "# í† í° ìˆ˜ë¡œ ë¹„ìš© ê³„ì‚°í•˜ê¸°\n",
    "def calculate_cost(text, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì˜ ì˜ˆìƒ ë¹„ìš© ê³„ì‚° (2024ë…„ 10ì›” ê¸°ì¤€)\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = len(encoding.encode(text))\n",
    "    \n",
    "    # ëª¨ë¸ë³„ ê°€ê²© (input ê¸°ì¤€, 1M í† í°ë‹¹ USD)\n",
    "    prices = {\n",
    "        \"gpt-4o\": 2.50,\n",
    "        \"gpt-4o-mini\": 0.150,\n",
    "        \"gpt-3.5-turbo\": 0.50,\n",
    "    }\n",
    "    \n",
    "    price_per_token = prices.get(model, 0.150) / 1_000_000\n",
    "    cost = tokens * price_per_token\n",
    "    \n",
    "    return {\n",
    "        \"tokens\": tokens,\n",
    "        \"cost_usd\": cost,\n",
    "        \"cost_krw\": cost * 1300  # í™˜ìœ¨ ëŒ€ëµ 1300ì› ê°€ì •\n",
    "    }\n",
    "\n",
    "# ì˜ˆì‹œ\n",
    "long_text = \"\"\"ì¸ê³µì§€ëŠ¥(AI)ì€ í˜„ëŒ€ ì‚¬íšŒì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤. \n",
    "íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œëŠ” GPTì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ í˜ì‹ ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì¸ê°„ê³¼ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "result = calculate_cost(long_text, \"gpt-4o-mini\")\n",
    "print(f\"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(long_text)} ê¸€ì\")\n",
    "print(f\"í† í° ìˆ˜: {result['tokens']}\")\n",
    "print(f\"ì˜ˆìƒ ë¹„ìš©: ${result['cost_usd']:.6f} (ì•½ {result['cost_krw']:.4f}ì›)\")\n",
    "print(f\"\\nğŸ’¡ 1ë§Œ ê¸€ì ì²˜ë¦¬ ì‹œ ì˜ˆìƒ ë¹„ìš©: ì•½ {result['cost_krw'] * 10000 / len(long_text):.2f}ì›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chat-header",
   "metadata": {},
   "source": [
    "## 3. ê¸°ë³¸ Chat Completions API\n",
    "\n",
    "### API ê¸°ë³¸ êµ¬ì¡°\n",
    "```python\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",              # í•„ìˆ˜: ì‚¬ìš©í•  ëª¨ë¸\n",
    "    messages=[...],                   # í•„ìˆ˜: ëŒ€í™” ë‚´ìš©\n",
    "    temperature=0.7,                  # ì„ íƒ: ì°½ì˜ì„± (0.0~2.0)\n",
    "    max_tokens=150,                   # ì„ íƒ: ìµœëŒ€ ì¶œë ¥ í† í°\n",
    "    top_p=1.0,                       # ì„ íƒ: ëˆ„ì  í™•ë¥ \n",
    "    frequency_penalty=0.0,            # ì„ íƒ: ë°˜ë³µ ì–µì œ (0.0~2.0)\n",
    "    presence_penalty=0.0,             # ì„ íƒ: ì£¼ì œ ë‹¤ì–‘ì„± (0.0~2.0)\n",
    "    stop=[\"\\n\", \"###\"],              # ì„ íƒ: ìƒì„± ì¤‘ë‹¨ ì¡°ê±´\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "first-call",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API í˜¸ì¶œ ì„±ê³µ!\n",
      "\n",
      "AI ì‘ë‹µ: ì•ˆë…•í•˜ì„¸ìš”! APIë¥¼ ì²˜ìŒ ì‚¬ìš©í•˜ì‹ ë‹¤ë‹ˆ í¥ë¯¸ë¡œìš´ ê²½í—˜ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì–´ë–¤ APIë¥¼ ì‚¬ìš©í•˜ê³  ê³„ì‹ ê°€ìš”? ë˜ëŠ” API ì‚¬ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”? ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\n",
      "ğŸ“Š ì‚¬ìš© í†µê³„:\n",
      "  - ì…ë ¥ í† í°: 19\n",
      "  - ì¶œë ¥ í† í°: 57\n",
      "  - ì´ í† í°: 76\n"
     ]
    }
   ],
   "source": [
    "# ì²« ë²ˆì§¸ API í˜¸ì¶œ\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! ì²˜ìŒìœ¼ë¡œ APIë¥¼ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤.\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… API í˜¸ì¶œ ì„±ê³µ!\\n\")\n",
    "    print(\"AI ì‘ë‹µ:\", response.choices[0].message.content)\n",
    "    print(f\"\\nğŸ“Š ì‚¬ìš© í†µê³„:\")\n",
    "    print(f\"  - ì…ë ¥ í† í°: {response.usage.prompt_tokens}\")\n",
    "    print(f\"  - ì¶œë ¥ í† í°: {response.usage.completion_tokens}\")\n",
    "    print(f\"  - ì´ í† í°: {response.usage.total_tokens}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "messages-structure",
   "metadata": {},
   "source": [
    "### Messages êµ¬ì¡° ì´í•´í•˜ê¸°\n",
    "\n",
    "**3ê°€ì§€ ì—­í• (role):**\n",
    "- `system`: AIì˜ í–‰ë™ ë°©ì‹, Instruction ë“± ì •ì˜\n",
    "- `user`: ì‚¬ìš©ìì˜ ì…ë ¥\n",
    "- `assistant`: AIì˜ ì´ì „ ì‘ë‹µ (ëŒ€í™” ê¸°ë¡)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "messages-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "í˜ë¥´ì†Œë‚˜ 1: ì¹œì ˆí•œ ì„ ìƒë‹˜\n",
      "Pythonì„ ë°°ìš°ëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **ê¸°ë³¸ ê°œë… ì´í•´í•˜ê¸°**:\n",
      "   - Pythonì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…(ë³€ìˆ˜, ë°ì´í„° íƒ€ì…, ì¡°ê±´ë¬¸, ë°˜ë³µë¬¸ ë“±)ì„ ë°°ìš°ì„¸ìš”. ì´ë¡ ì„ ë°°ìš°ëŠ” ê²ƒê³¼ í•¨ê»˜ ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ì‘ì„±í•´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì˜¨ë¼ì¸ ê°•ì¢Œ ìˆ˜ê°•í•˜ê¸°**:\n",
      "   - Coursera, edX, Udemyì™€ ê°™ì€ í”Œë«í¼ì—ì„œ Python ê°•ì¢Œë¥¼ ì°¾ì•„ ìˆ˜ê°•í•´ ë³´ì„¸ìš”. ì´ˆë³´ìë¥¼ ìœ„í•œ ê°•ì¢Œê°€ ë§ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ì±… ì½ê¸°**:\n",
      "   - \"Automate the Boring Stuff with Python\" ê°™ì€ ì…ë¬¸ì„œë‚˜ \"Python Crash Course\"ì™€ ê°™ì€ ì±…ì„ ì½ì–´ë³´ì„¸ìš”. ì‹¤ìŠµ ì˜ˆì œê°€ ë§ì•„ì„œ ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ì½”ë“œ ì‘ì„±í•˜ê¸°**:\n",
      "   - ì§ì ‘ ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ëŠ” ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤. ê°„ë‹¨í•œ í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, ê³„ì‚°ê¸°, ê°„ë‹¨í•œ ê²Œì„ ë“±ì„ ë§Œë“¤ì–´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **í”„ë¡œì íŠ¸ ì§„í–‰í•˜ê¸°**:\n",
      "   - ìì‹ ì´ ê´€ì‹¬ ìˆëŠ” ì£¼ì œë¥¼ ê°€ì§€ê³  ì‘ì€ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•´ ë³´ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, ì›¹ ìŠ¤í¬ë˜í•‘, ë°ì´í„° ë¶„ì„, ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ë“±ì„ ì‹œë„í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬í•˜ê¸°**:\n",
      "   - Stack Overflow, GitHub, Redditì˜ Python ê´€ë ¨ ì»¤ë®¤ë‹ˆí‹°ì— ì°¸ì—¬í•´ ë³´ì„¸ìš”. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì˜ ì§ˆë¬¸ì„ ë³´ê³  ë‹µë³€í•˜ê±°ë‚˜, ìì‹ ì˜ ì§ˆë¬¸ì„ ì˜¬ë ¤ì„œ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "7. **ê¾¸ì¤€í•œ ì—°ìŠµ**:\n",
      "   - ë§¤ì¼ ì¡°ê¸ˆì”©ì´ë¼ë„ ì½”ë”©í•˜ëŠ” ìŠµê´€ì„ ë“¤ì´ë©´ ì¢‹ìŠµë‹ˆë‹¤. ì½”ë”© ì—°ìŠµ ì‚¬ì´íŠ¸ì¸ LeetCode, HackerRank, Codewarsì—ì„œ ë¬¸ì œë¥¼ í’€ì–´ë³´ì„¸ìš”.\n",
      "\n",
      "8. **ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ì°¸ì—¬í•˜ê¸°**:\n",
      "   - GitHubì—ì„œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•´ ë³´ì„¸ìš”. ì‹¤ì œë¡œ ë‹¤ë¥¸ ì‚¬ëŒë“¤ê³¼ í˜‘ì—…í•˜ë©´ì„œ ë°°ìš°ëŠ” ì¢‹ì€ ê¸°íšŒê°€ ë  ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ê¾¸ì¤€í•¨ê³¼ í˜¸ê¸°ì‹¬ì…ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” ì–´ë µê²Œ ëŠê»´ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ê³„ì†í•´ì„œ ë„ì „í•˜ë‹¤ ë³´ë©´ ì ì  ë” ë‚˜ì•„ì§ˆ ê²ƒì…ë‹ˆë‹¤. ì¦ê²ê²Œ ë°°ìš°ì„¸ìš”!\n",
      "\n",
      "============================================================\n",
      "í˜ë¥´ì†Œë‚˜ 2: ì‹¤ì „ ê°œë°œì\n",
      "1. **ê¸°ë³¸ ê°œë… ì´í•´**: Pythonì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ë°ì´í„° êµ¬ì¡°(ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬, íŠœí”Œ ë“±)ë¥¼ ìµíˆì„¸ìš”.\n",
      "2. **ì˜¨ë¼ì¸ ê°•ì˜**: Coursera, Udemy, edX ë“±ì—ì„œ ê°•ì˜ë¥¼ ìˆ˜ê°•í•˜ì„¸ìš”.\n",
      "3. **í”„ë¡œì íŠ¸ ì§„í–‰**: ê°„ë‹¨í•œ í”„ë¡œì íŠ¸(ì›¹ ìŠ¤í¬ë˜í¼, ë°ì´í„° ë¶„ì„, ì›¹ ì•± ë“±)ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”.\n",
      "4. **ì½”ë“œ ì½ê¸°**: ë‹¤ë¥¸ ì‚¬ëŒì˜ ì½”ë“œë¥¼ ì½ê³  ì´í•´í•˜ì„¸ìš”. GitHubì—ì„œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.\n",
      "5. **ë¬¸ì„œí™”**: Python ê³µì‹ ë¬¸ì„œì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œë¥¼ ì •ê¸°ì ìœ¼ë¡œ ì°¸ê³ í•˜ì„¸ìš”.\n",
      "6. **ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬**: Stack Overflow, Reddit, Python í¬ëŸ¼ì— ì°¸ì—¬í•˜ì—¬ ì§ˆë¬¸í•˜ê³  ë‹µë³€í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# System ë©”ì‹œì§€ì˜ í˜\n",
    "def test_system_message(system_content, user_content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ê°™ì€ ì§ˆë¬¸, ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜\n",
    "question = \"Pythonì„ ë°°ìš°ëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€?\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"í˜ë¥´ì†Œë‚˜ 1: ì¹œì ˆí•œ ì„ ìƒë‹˜\")\n",
    "print(test_system_message(\n",
    "    \"ë‹¹ì‹ ì€ ì´ˆë³´ìë¥¼ ìœ„í•œ ì¹œì ˆí•œ í”„ë¡œê·¸ë˜ë° ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    question\n",
    "))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"í˜ë¥´ì†Œë‚˜ 2: ì‹¤ì „ ê°œë°œì\")\n",
    "print(test_system_message(\n",
    "    \"ë‹¹ì‹ ì€ 10ë…„ì°¨ ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤. ì‹¤ë¬´ ê´€ì ì—ì„œ í•µì‹¬ë§Œ ê°„ë‹¨íˆ ë‹µë³€í•˜ì„¸ìš”.\",\n",
    "    question\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conversation-history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: íŒŒì´ì¬ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜\n",
      "AI: íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¼ë°˜ì ì¸ ë‘ ê°€ì§€ ë°©ë²•ì€ `sort()` ë©”ì„œë“œì™€ `sorted()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "1. **`sort()` ë©”ì„œë“œ**:\n",
      "   - `sort()`ëŠ” ë¦¬ìŠ¤íŠ¸ ê°ì²´ì˜ ë©”ì„œë“œë¡œ, ë¦¬ìŠ¤íŠ¸ ìì²´ë¥¼ ì •ë ¬í•©ë‹ˆë‹¤. ì´ ë©”ì„œë“œëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ë¯€ë¡œ ë°˜í™˜ê°’ì€ `None`ì…ë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   my_list = [5, 2, 9, 1, 5, 6]\n",
      "   my_list.sort()  # ë¦¬ìŠ¤íŠ¸ë¥¼ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬\n",
      "   print(my_list)   # ì¶œë ¥: [1, 2, 5, 5, 6, 9]\n",
      "   ```\n",
      "\n",
      "   - ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ë ¤ë©´ `reverse=True` ì¸ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   my_list.sort(reverse=True)\n",
      "   print(my_list)   # ì¶œë ¥: [9, 6, 5, 5, 2, 1]\n",
      "   ```\n",
      "\n",
      "2. **`sorted()` í•¨ìˆ˜**:\n",
      "   - `sorted()` í•¨ìˆ˜ëŠ” iterable(ë°˜ë³µ ê°€ëŠ¥í•œ ê°ì²´)ì„ ì¸ìë¡œ ë°›ì•„ ì •ë ¬ëœ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì›ë˜ ë¦¬ìŠ¤íŠ¸ëŠ” ë³€ê²½ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   my_list = [5, 2, 9, 1, 5, 6]\n",
      "   sorted_list = sorted(my_list)  # ìƒˆë¡œìš´ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
      "   print(sorted_list)  # ì¶œë ¥: [1, 2, 5, 5, 6, 9]\n",
      "   print(my_list)      # ì›ë˜ ë¦¬ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ: [5, 2, 9, 1, 5, 6]\n",
      "   ```\n",
      "\n",
      "   - ë§ˆì°¬ê°€ì§€ë¡œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   sorted_list_desc = sorted(my_list, reverse=True)\n",
      "   print(sorted_list_desc)  # ì¶œë ¥: [9, 6, 5, 5, 2, 1]\n",
      "   ```\n",
      "\n",
      "3. **ì •ë ¬ ê¸°ì¤€ ì§€ì •í•˜ê¸°**:\n",
      "   - `key` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë ¬ ê¸°ì¤€ì„ ì§€ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¬¸ìì—´ì˜ ê¸¸ì´ì— ë”°ë¼ ì •ë ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   words = [\"banana\", \"pie\", \"Washington\", \"book\"]\n",
      "   words.sort(key=len)  # ë¬¸ìì—´ì˜ ê¸¸ì´ì— ë”°ë¼ ì •ë ¬\n",
      "   print(words)  # ì¶œë ¥: ['pie', 'book', 'banana', 'Washington']\n",
      "   ```\n",
      "\n",
      "ì´ì™€ ê°™ì´ íŒŒì´ì¬ì—ì„œëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì‰½ê³  ìœ ì—°í•˜ê²Œ ì •ë ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤!\n",
      "\n",
      "User: ì—­ìˆœìœ¼ë¡œëŠ” ì–´ë–»ê²Œ í•´?\n",
      "AI: ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” ë°©ë²•ì—ë„ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì— ëª‡ ê°€ì§€ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.\n",
      "\n",
      "1. **`sort()` ë©”ì„œë“œ ì‚¬ìš©**:\n",
      "   - `sort()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `reverse=True` ì¸ìë¥¼ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   my_list = [5, 2, 9, 1, 5, 6]\n",
      "   my_list.sort(reverse=True)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬\n",
      "   print(my_list)  # ì¶œë ¥: [9, 6, 5, 5, 2, 1]\n",
      "   ```\n",
      "\n",
      "2. **`sorted()` í•¨ìˆ˜ ì‚¬ìš©**:\n",
      "   - `sorted()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—­ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ `reverse=True` ì¸ìë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   my_list = [5, 2, 9, 1, 5, 6]\n",
      "   sorted_list = sorted(my_list, reverse=True)  # ìƒˆë¡œìš´ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
      "   print(sorted_list)  # ì¶œë ¥: [9, 6, 5, 5, 2, 1]\n",
      "   ```\n",
      "\n",
      "3. **`reverse()` ë©”ì„œë“œ ì‚¬ìš©**:\n",
      "   - ì´ë¯¸ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ë’¤ì§‘ê³  ì‹¶ë‹¤ë©´ `reverse()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë©”ì„œë“œëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   my_list = [1, 2, 3, 4, 5]\n",
      "   my_list.reverse()  # ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ë’¤ì§‘ìŒ\n",
      "   print(my_list)  # ì¶œë ¥: [5, 4, 3, 2, 1]\n",
      "   ```\n",
      "\n",
      "4. **ìŠ¬ë¼ì´ì‹± ì‚¬ìš©**:\n",
      "   - ìŠ¬ë¼ì´ì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì›ë˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³  ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "   ```python\n",
      "   my_list = [1, 2, 3, 4, 5]\n",
      "   reversed_list = my_list[::-1]  # ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ ì—­ìˆœ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
      "   print(reversed_list)  # ì¶œë ¥: [5, 4, 3, 2, 1]\n",
      "   print(my_list)        # ì›ë˜ ë¦¬ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ: [1, 2, 3, 4, 5]\n",
      "   ```\n",
      "\n",
      "ìœ„ì˜ ë°©ë²•ë“¤ ì¤‘ì—ì„œ í•„ìš”ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤!\n",
      "\n",
      "\n",
      "í˜„ì¬ ëŒ€í™” ê¸¸ì´: 5 ë©”ì‹œì§€\n"
     ]
    }
   ],
   "source": [
    "# ëŒ€í™” ê¸°ë¡ ìœ ì§€í•˜ê¸°\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "]\n",
    "\n",
    "def chat(user_message):\n",
    "    \"\"\"ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ë©° ì±„íŒ…\"\"\"\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # API í˜¸ì¶œ\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=conversation,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # AI ì‘ë‹µ ì¶”ê°€\n",
    "    ai_message = response.choices[0].message.content\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": ai_message})\n",
    "    \n",
    "    return ai_message\n",
    "\n",
    "# ì—°ì† ëŒ€í™” í…ŒìŠ¤íŠ¸\n",
    "print(\"User: íŒŒì´ì¬ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜\")\n",
    "print(f\"AI: {chat('íŒŒì´ì¬ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜')}\\n\")\n",
    "\n",
    "print(\"User: ì—­ìˆœìœ¼ë¡œëŠ” ì–´ë–»ê²Œ í•´?\")\n",
    "print(f\"AI: {chat('ì—­ìˆœìœ¼ë¡œëŠ” ì–´ë–»ê²Œ í•´?')}\\n\")\n",
    "\n",
    "print(f\"\\ní˜„ì¬ ëŒ€í™” ê¸¸ì´: {len(conversation)} ë©”ì‹œì§€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temperature-section",
   "metadata": {},
   "source": [
    "### Temperature - ì°½ì˜ì„± ì¡°ì ˆ\n",
    "\n",
    "- `0.0`: ë§¤ìš° ê²°ì •ì , ì¼ê´€ì„± ìˆëŠ” ë‹µë³€\n",
    "- `0.3-0.5`: ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ì— ì í•©\n",
    "- `0.7-0.9`: ê· í˜•ì¡íŒ ì°½ì˜ì„± (ê¸°ë³¸ê°’)\n",
    "- `1.0-2.0`: ë§¤ìš° ì°½ì˜ì , ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "temperature-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ¡ï¸ Temperature 0.0:\n",
      "ìš°ì£¼ ì •ê±°ì¥ì—ì„œ ë°”ë¼ë³¸ ì§€êµ¬ëŠ” ë§ˆì¹˜ í‘¸ë¥¸ ë³´ì„ì²˜ëŸ¼ ë°˜ì§ì´ë©°, ê·¸ ì•„ë˜ì—ì„œ ìŠí˜€ì§„ ê¸°ì–µë“¤ì´ ì†Œìš©ëŒì´ì¹˜ëŠ” ë“¯í–ˆë‹¤.\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸŒ¡ï¸ Temperature 0.5:\n",
      "ìš°ì£¼ë¥¼ ê°€ë¡œì§€ë¥´ëŠ” ì€í•˜ì˜ ì–´ë‘  ì†ì—ì„œ, ì¸ë¥˜ëŠ” ì²˜ìŒìœ¼ë¡œ ë³„ë¹›ì„ ë”°ë¼ ë‚˜ì•„ê°€ëŠ” ì—¬í–‰ì„ ì‹œì‘í–ˆë‹¤.\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸŒ¡ï¸ Temperature 1.0:\n",
      "í‘¸ë¥¸ ì§€êµ¬ë¥¼ ë’¤ë¡œí•˜ê³ , ê·¸ë…€ì˜ ìš°ì£¼ì„ ì€ ì€í•˜ì˜ ì–´ë‘  ì†ìœ¼ë¡œ ì¡°ìš©íˆ ìŠ¤ë©°ë“¤ì–´ ê°”ë‹¤.\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸŒ¡ï¸ Temperature 1.5:\n",
      "ë¨¼ ìš°ì£¼ ì´ìƒì—ì„œ ìˆ˜ì—†ì´ ë°˜ì§ì´ëŠ” ë³„ë“¤ ì‚¬ì´ë¡œ, ì§€êµ¬ì—ì„œ ë¡œì¼“ì— ëª¸ì„ ì‹¤ì€ í•œ ì†Œë…„ì€ í•œ í¸ì˜ ê¿ˆì„ ì•ˆê³  ì¶œë°œí–ˆë‹¤.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"ìš°ì£¼ ì—¬í–‰ì„ ì£¼ì œë¡œ í•œ ë‹¨í¸ ì†Œì„¤ì˜ ì²« ë¬¸ì¥ì„ ì¨ì¤˜\"\n",
    "\n",
    "temperatures = [0.0, 0.5, 1.0, 1.5]\n",
    "\n",
    "for temp in temperatures:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temp,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    print(f\"\\nğŸŒ¡ï¸ Temperature {temp}:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-header",
   "metadata": {},
   "source": [
    "## 4. Streaming API - ì‹¤ì‹œê°„ ì‘ë‹µ\n",
    "\n",
    "ì¼ë°˜ APIëŠ” ëª¨ë“  ë‹µë³€ì´ ì™„ì„±ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì•¼ í•˜ì§€ë§Œ, Streamingì„ ì‚¬ìš©í•˜ë©´ ChatGPTì²˜ëŸ¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ê°€ ìƒì„±ë©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "streaming-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ì¸ê³µì§€ëŠ¥ì€ ë‹¤ì–‘í•œ ì‚°ì—…ê³¼ ì¼ìƒìƒí™œì—ì„œ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ì´ëŒ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤. íŠ¹íˆ, ìë™í™”ì™€ ë°ì´í„° ë¶„ì„ì„ í†µí•´ ì¸ê°„ì˜ ìƒì‚°ì„±ì„ ë†’ì´ê³ , ë³´ë‹¤ ê°œì¸í™”ëœ ì„œë¹„ìŠ¤ì™€ ì†”ë£¨ì…˜ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìœ¤ë¦¬ì  ë¬¸ì œì™€ ì¼ìë¦¬ ë³€í™”ì™€ ê°™ì€ ë„ì „ ê³¼ì œê°€ ë™ë°˜ë  ê²ƒì´ë©°, ì´ì— ëŒ€í•œ ì‚¬íšŒì  ë…¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë°\n",
    "print(\"AI: \", end=\"\", flush=True)\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ 3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\"}],\n",
    "    stream=True,  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print()  # ì¤„ë°”ê¿ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "streaming-advanced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜(List Comprehension)ì€ íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìƒì„±í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì „í†µì ì¸ ë£¨í”„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ê°„ë‹¨í•˜ê³  ì§ê´€ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ êµ¬ë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "[ì‹ for í•­ëª© in iterable if ì¡°ê±´]\n",
      "```\n",
      "\n",
      "ì´ êµ¬ë¬¸ì€ `iterable`ì—ì„œ ê° `í•­ëª©`ì„ ë°˜ë³µ(iterate)í•˜ë©´ì„œ íŠ¹ì • `ì¡°ê±´`ì„ ë§Œì¡±í•˜ëŠ” ê²½ìš°ì—ë§Œ `ì‹`ì— ì˜í•´ ìƒì„±ëœ ê°’ì„ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "### ì˜ˆì œ 1: ì œê³± ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°\n",
      "\n",
      "1ë¶€í„° 10ê¹Œì§€ì˜ ì •ìˆ˜ì˜ ì œê³±ì„ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "squares = [x**2 for x in range(1, 11)]\n",
      "print(squares)  # ì¶œë ¥: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "```\n",
      "\n",
      "### ì˜ˆì œ 2: ì§ìˆ˜ í•„í„°ë§\n",
      "\n",
      "1ë¶€í„° 20ê¹Œì§€ì˜ ìˆ«ì ì¤‘ì—ì„œ ì§ìˆ˜ë§Œ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "evens = [x for x in range(1, 21) if x % 2 == 0]\n",
      "print(evens)  # ì¶œë ¥: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
      "```\n",
      "\n",
      "### ì˜ˆì œ 3: ë¬¸ìì—´ ê¸¸ì´ ë¦¬ìŠ¤íŠ¸\n",
      "\n",
      "ì£¼ì–´ì§„ ë¬¸ìì—´ ëª©ë¡ì—ì„œ ê° ë¬¸ìì—´ì˜ ê¸¸ì´ë¥¼ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "strings = [\"apple\", \"banana\", \"cherry\"]\n",
      "lengths = [len(s) for s in strings]\n",
      "print(lengths)  # ì¶œë ¥: [5, 6, 6]\n",
      "```\n",
      "\n",
      "ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ì„ ì‚¬ìš©í•˜ë©´ ì½”ë“œê°€ ë” ê°„ê²°í•˜ê³  ê°€ë…ì„±ì´ ì¢‹ì•„ì§€ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì€ íŒŒì´ì¬ì˜ \"í•œ ì¤„ë¡œ í•´ê²°í•˜ëŠ”\" ì ‘ê·¼ ë°©ì‹ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š í†µê³„:\n",
      "  - ì‘ë‹µ ê¸¸ì´: 896 ê¸€ì\n",
      "  - í† í° ìˆ˜: 444\n",
      "  - ì†Œìš” ì‹œê°„: 8.58ì´ˆ\n",
      "  - ì²˜ë¦¬ ì†ë„: 51.8 í† í°/ì´ˆ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜(List Comprehension)ì€ íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìƒì„±í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì „í†µì ì¸ ë£¨í”„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ê°„ë‹¨í•˜ê³  ì§ê´€ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ êµ¬ë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n```python\\n[ì‹ for í•­ëª© in iterable if ì¡°ê±´]\\n```\\n\\nì´ êµ¬ë¬¸ì€ `iterable`ì—ì„œ ê° `í•­ëª©`ì„ ë°˜ë³µ(iterate)í•˜ë©´ì„œ íŠ¹ì • `ì¡°ê±´`ì„ ë§Œì¡±í•˜ëŠ” ê²½ìš°ì—ë§Œ `ì‹`ì— ì˜í•´ ìƒì„±ëœ ê°’ì„ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n### ì˜ˆì œ 1: ì œê³± ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°\\n\\n1ë¶€í„° 10ê¹Œì§€ì˜ ì •ìˆ˜ì˜ ì œê³±ì„ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n```python\\nsquares = [x**2 for x in range(1, 11)]\\nprint(squares)  # ì¶œë ¥: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\\n```\\n\\n### ì˜ˆì œ 2: ì§ìˆ˜ í•„í„°ë§\\n\\n1ë¶€í„° 20ê¹Œì§€ì˜ ìˆ«ì ì¤‘ì—ì„œ ì§ìˆ˜ë§Œ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n```python\\nevens = [x for x in range(1, 21) if x % 2 == 0]\\nprint(evens)  # ì¶œë ¥: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\\n```\\n\\n### ì˜ˆì œ 3: ë¬¸ìì—´ ê¸¸ì´ ë¦¬ìŠ¤íŠ¸\\n\\nì£¼ì–´ì§„ ë¬¸ìì—´ ëª©ë¡ì—ì„œ ê° ë¬¸ìì—´ì˜ ê¸¸ì´ë¥¼ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n```python\\nstrings = [\"apple\", \"banana\", \"cherry\"]\\nlengths = [len(s) for s in strings]\\nprint(lengths)  # ì¶œë ¥: [5, 6, 6]\\n```\\n\\në¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ì„ ì‚¬ìš©í•˜ë©´ ì½”ë“œê°€ ë” ê°„ê²°í•˜ê³  ê°€ë…ì„±ì´ ì¢‹ì•„ì§€ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì€ íŒŒì´ì¬ì˜ \"í•œ ì¤„ë¡œ í•´ê²°í•˜ëŠ”\" ì ‘ê·¼ ë°©ì‹ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def stream_chat(prompt, show_stats=True):\n",
    "    \"\"\"í†µê³„ì™€ í•¨ê»˜ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…\"\"\"\n",
    "    start_time = time.time()\n",
    "    full_response = \"\"\n",
    "    \n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    print(\"AI: \", end=\"\", flush=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end=\"\", flush=True)\n",
    "            full_response += content\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if show_stats:\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "        tokens = len(encoding.encode(full_response))\n",
    "        print(f\"\\n\\nğŸ“Š í†µê³„:\")\n",
    "        print(f\"  - ì‘ë‹µ ê¸¸ì´: {len(full_response)} ê¸€ì\")\n",
    "        print(f\"  - í† í° ìˆ˜: {tokens}\")\n",
    "        print(f\"  - ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ\")\n",
    "        print(f\"  - ì²˜ë¦¬ ì†ë„: {tokens/elapsed_time:.1f} í† í°/ì´ˆ\")\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "stream_chat(\"Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ì„ ì„¤ëª…í•˜ê³  3ê°€ì§€ ì˜ˆì œë¥¼ ë³´ì—¬ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "streaming-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1ï¸âƒ£ ì¼ë°˜ API (ì „ì²´ ì‘ë‹µ ëŒ€ê¸°)\n",
      "\n",
      "â±ï¸ ì²« ì‘ë‹µê¹Œì§€: 12.15ì´ˆ\n",
      "ì¸ê³µì§€ëŠ¥(AI)ì˜ ì—­ì‚¬ëŠ” 20ì„¸ê¸° ì¤‘ë°˜ìœ¼ë¡œ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°‘ë‹ˆë‹¤. 1956ë…„ ë‹¤íŠ¸ë¨¸ìŠ¤ íšŒì˜ì—ì„œ ì¡´ ë§¤ì¹´ì‹œ, ë§ˆë¹ˆ ë¯¼ìŠ¤í‚¤, ë„¤ì´ì„  ë¯¸ë¥´ë³¼ë“œ ë“±ì´ ëª¨ì—¬ AIë¼ëŠ” ìš©ì–´ë¥¼ ì²˜ìŒ ì œì•ˆí–ˆìŠµë‹ˆë‹¤....\n",
      "\n",
      "============================================================\n",
      "2ï¸âƒ£ ìŠ¤íŠ¸ë¦¬ë° API (ì‹¤ì‹œê°„ ìƒì„±)\n",
      "\n",
      "ì¸ê³µì§€ëŠ¥(AI)ì˜ ì—­ì‚¬ëŠ” 20ì„¸ê¸° ì¤‘ë°˜ìœ¼ë¡œ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°‘ë‹ˆë‹¤. 1956ë…„ ë‹¤íŠ¸ë¨¸ìŠ¤ ëŒ€í•™ì—ì„œ ì—´ë¦° AI ì—¬ë¦„ ì›Œí¬ìˆì€ ì¸ê³µì§€ëŠ¥ ì—°êµ¬ì˜ ì‹œì‘ì„ ì•Œë¦¬ëŠ”\n",
      "\n",
      "â±ï¸ ì²« ì‘ë‹µê¹Œì§€: 0.62ì´ˆ (í›¨ì”¬ ë¹ ë¦„!)\n"
     ]
    }
   ],
   "source": [
    "# ì¼ë°˜ vs ìŠ¤íŠ¸ë¦¬ë° ì²´ê° ë¹„êµ\n",
    "prompt = \"ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ 5ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•´ì¤˜\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"1ï¸âƒ£ ì¼ë°˜ API (ì „ì²´ ì‘ë‹µ ëŒ€ê¸°)\\n\")\n",
    "start = time.time()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    ")\n",
    "print(f\"â±ï¸ ì²« ì‘ë‹µê¹Œì§€: {time.time() - start:.2f}ì´ˆ\")\n",
    "print(response.choices[0].message.content[:100] + \"...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2ï¸âƒ£ ìŠ¤íŠ¸ë¦¬ë° API (ì‹¤ì‹œê°„ ìƒì„±)\\n\")\n",
    "start = time.time()\n",
    "first_chunk_time = None\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for i, chunk in enumerate(stream):\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        if first_chunk_time is None:\n",
    "            first_chunk_time = time.time() - start\n",
    "        if i < 50:  # ì²˜ìŒ ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(f\"\\n\\nâ±ï¸ ì²« ì‘ë‹µê¹Œì§€: {first_chunk_time:.2f}ì´ˆ (í›¨ì”¬ ë¹ ë¦„!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding-header",
   "metadata": {},
   "source": [
    "## 5. Embedding API - í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ\n",
    "\n",
    "Embeddingì€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´:\n",
    "- í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "- ì˜ë¯¸ì  ê²€ìƒ‰ (Semantic Search)\n",
    "- í´ëŸ¬ìŠ¤í„°ë§, ë¶„ë¥˜\n",
    "\n",
    "**ëª¨ë¸:** `text-embedding-3-small` (ì €ë ´), `text-embedding-3-large` (ì •í™•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "embedding-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ìŠ¤íŠ¸: ì¸ê³µì§€ëŠ¥ì€ ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
      "ë²¡í„° ì°¨ì›: 1536\n",
      "ë²¡í„° ì•ë¶€ë¶„: [-0.01845400594174862, 0.030923428013920784, -0.02049209736287594, 0.005952158011496067, 0.013340245001018047, -0.04431925714015961, -0.004465276375412941, 0.04461570829153061, -0.0016061562346294522, -0.006114278919994831]\n",
      "\n",
      "ğŸ’¡ ì´ ë²¡í„°ëŠ” í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ìˆ«ìë¡œ í‘œí˜„í•œ ê²ƒì…ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ì„ë² ë”©\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# ì˜ˆì‹œ\n",
    "text = \"ì¸ê³µì§€ëŠ¥ì€ ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.\"\n",
    "embedding = get_embedding(text)\n",
    "\n",
    "print(f\"í…ìŠ¤íŠ¸: {text}\")\n",
    "print(f\"ë²¡í„° ì°¨ì›: {len(embedding)}\")\n",
    "print(f\"ë²¡í„° ì•ë¶€ë¶„: {embedding[:10]}\")\n",
    "print(f\"\\nğŸ’¡ ì´ ë²¡í„°ëŠ” í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ìˆ«ìë¡œ í‘œí˜„í•œ ê²ƒì…ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "embedding-similarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì¤€ ë¬¸ì¥: 'ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë›°ì–´ë†€ê³  ìˆë‹¤'\n",
      "\n",
      "ìœ ì‚¬ë„ ì ìˆ˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬):\n",
      "  1.0000 - ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë›°ì–´ë†€ê³  ìˆë‹¤\n",
      "  0.3027 - ê°œê°€ ì•¼ì™¸ì—ì„œ ë†€ê³  ìˆë‹¤\n",
      "  0.4248 - ê³ ì–‘ì´ê°€ ì§‘ì—ì„œ ìê³  ìˆë‹¤\n",
      "  0.1319 - Pythonì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì´ë‹¤\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# ì—¬ëŸ¬ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ ë¹„êµ\n",
    "sentences = [\n",
    "    \"ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë›°ì–´ë†€ê³  ìˆë‹¤\",\n",
    "    \"ê°œê°€ ì•¼ì™¸ì—ì„œ ë†€ê³  ìˆë‹¤\",\n",
    "    \"ê³ ì–‘ì´ê°€ ì§‘ì—ì„œ ìê³  ìˆë‹¤\",\n",
    "    \"Pythonì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì´ë‹¤\",\n",
    "]\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì¥ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "embeddings = [get_embedding(s) for s in sentences]\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë¬¸ì¥ê³¼ ë‚˜ë¨¸ì§€ ë¬¸ì¥ë“¤ì˜ ìœ ì‚¬ë„\n",
    "base_sentence = sentences[0]\n",
    "print(f\"ê¸°ì¤€ ë¬¸ì¥: '{base_sentence}'\\n\")\n",
    "print(\"ìœ ì‚¬ë„ ì ìˆ˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬):\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[0], embeddings[i])\n",
    "    print(f\"  {similarity:.4f} - {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "embedding-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'AI í•™ìŠµ ë°©ë²•'\n",
      "  [0.3559] ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤\n",
      "  [0.3175] Pythonì€ ê°„ê²°í•˜ê³  ë°°ìš°ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤\n",
      "  [0.3095] ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê²Œ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'í”„ë¡œê·¸ë˜ë° ë°°ìš°ê¸°'\n",
      "  [0.4961] Pythonì€ ê°„ê²°í•˜ê³  ë°°ìš°ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤\n",
      "  [0.3243] JavaScriptëŠ” ì›¹ ê°œë°œì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤\n",
      "  [0.2123] ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ì–¸ì–´ ì´í•´ ê¸°ìˆ '\n",
      "  [0.6288] ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê²Œ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤\n",
      "  [0.3627] Pythonì€ ê°„ê²°í•˜ê³  ë°°ìš°ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤\n",
      "  [0.3366] JavaScriptëŠ” ì›¹ ê°œë°œì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì „ ì˜ˆì œ: ê°„ë‹¨í•œ ì˜ë¯¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n",
    "documents = [\n",
    "    \"Pythonì€ ê°„ê²°í•˜ê³  ë°°ìš°ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤\",\n",
    "    \"ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤\",\n",
    "    \"ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê²Œ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤\",\n",
    "    \"JavaScriptëŠ” ì›¹ ê°œë°œì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤\",\n",
    "]\n",
    "\n",
    "# ëª¨ë“  ë¬¸ì„œ ì„ë² ë”©\n",
    "doc_embeddings = [get_embedding(doc) for doc in documents]\n",
    "\n",
    "def search(query, top_k=3):\n",
    "    \"\"\"ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰\"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    # ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    similarities = [\n",
    "        cosine_similarity(query_embedding, doc_emb) \n",
    "        for doc_emb in doc_embeddings\n",
    "    ]\n",
    "    \n",
    "    # ìƒìœ„ kê°œ ê²°ê³¼\n",
    "    results = sorted(\n",
    "        zip(documents, similarities), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )[:top_k]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "queries = [\n",
    "    \"AI í•™ìŠµ ë°©ë²•\",\n",
    "    \"í”„ë¡œê·¸ë˜ë° ë°°ìš°ê¸°\",\n",
    "    \"ì–¸ì–´ ì´í•´ ê¸°ìˆ \"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nğŸ” ê²€ìƒ‰ì–´: '{query}'\")\n",
    "    results = search(query)\n",
    "    for doc, score in results:\n",
    "        print(f\"  [{score:.4f}] {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-comparison",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "### ì£¼ìš” ëª¨ë¸ë“¤ (2024ë…„ 10ì›” ê¸°ì¤€)\n",
    "\n",
    "| ëª¨ë¸ | íŠ¹ì§• | ì…ë ¥ ê°€ê²©* | ì¶œë ¥ ê°€ê²©* | ì¶”ì²œ ìš©ë„ |\n",
    "|------|------|-----------|-----------|----------|\n",
    "| **gpt-4o** | ìµœì‹ , ìµœê³  ì„±ëŠ¥ | $2.50 | $10.00 | ë³µì¡í•œ ì¶”ë¡ , ì „ë¬¸ ì‘ì—… |\n",
    "| **gpt-4o-mini** | ê°€ì„±ë¹„ ìµœê³  | $0.150 | $0.600 | ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ ì‘ì—… |\n",
    "| **gpt-3.5-turbo** | ë¹ ë¥´ê³  ì €ë ´ | $0.50 | $1.50 | ê°„ë‹¨í•œ ì‘ì—…, ëŒ€í™” |\n",
    "\n",
    "*ê°€ê²©: 1M í† í°ë‹¹ USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "model-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ëª¨ë¸: gpt-4o-mini\n",
      "============================================================\n",
      "ê°ì • ë¶„ì„ ê²°ê³¼: **ë¶€ì •**\n",
      "\n",
      "ì´ìœ : í…ìŠ¤íŠ¸ëŠ” ì œí’ˆ ë°°ì†¡ì´ ë¹¨ëë‹¤ëŠ” ê¸ì •ì ì¸ ìš”ì†Œë¡œ ì‹œì‘í•˜ì§€ë§Œ, ì´ì–´ì„œ í’ˆì§ˆì´ ê¸°ëŒ€ì— ë¯¸ì¹˜ì§€ ëª»í•˜ê³  ê°€ê²© ëŒ€ë¹„ ì•„ì‰¬ìš´ ì ì´ ë§ë‹¤ëŠ” ë¶€ì •ì ì¸ í‰ê°€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ë¶€ì •ì ì¸ ê°ì •ì´ ì§€ë°°ì ì´ë¯€ë¡œ ë¶€ì •ìœ¼ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "â±ï¸ ì‘ë‹µ ì‹œê°„: 4.93ì´ˆ\n",
      "ğŸ“Š í† í° ì‚¬ìš©: 158\n",
      "\n",
      "============================================================\n",
      "ëª¨ë¸: gpt-4o\n",
      "============================================================\n",
      "ì´ í…ìŠ¤íŠ¸ì˜ ê°ì •ì€ ë¶€ì •ìœ¼ë¡œ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ìœ :\n",
      "1. \"ì œí’ˆ ë°°ì†¡ì€ ë¹¨ëì§€ë§Œ\"ì´ë¼ëŠ” í‘œí˜„ì—ì„œ ë°°ì†¡ ì†ë„ì— ëŒ€í•œ ê¸ì •ì ì¸ ë¶€ë¶„ì´ ì–¸ê¸‰ë˜ì—ˆìœ¼ë‚˜, ì´ëŠ” ì „ì²´ì ì¸ í‰ê°€ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "2. \"í’ˆì§ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì³¤ìŠµë‹ˆë‹¤\"ë¼ëŠ” ë¬¸ì¥ì—ì„œ ì œí’ˆì˜ í’ˆì§ˆì— ëŒ€í•œ ì‹¤ë§ê°ì´ ë“œëŸ¬ë‚©ë‹ˆë‹¤.\n",
      "3. \"ê°€ê²© ëŒ€ë¹„ ì•„ì‰¬ìš´ ì ì´ ë§ë„¤ìš”\"ë¼ëŠ” í‘œí˜„ì€ ê°€ê²©ì— ë¹„í•´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šë‹¤ëŠ” ë¶€ì •ì ì¸ í‰ê°€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ì´ìœ ë“¤ë¡œ ì¸í•´ ì „ì²´ì ì¸ ê°ì •ì€ ë¶€ì •ì ì´ë¼ê³  íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "â±ï¸ ì‘ë‹µ ì‹œê°„: 3.58ì´ˆ\n",
      "ğŸ“Š í† í° ì‚¬ìš©: 225\n",
      "\n",
      "============================================================\n",
      "ëª¨ë¸: gpt-3.5-turbo\n",
      "============================================================\n",
      "ë¶€ì •\n",
      "\n",
      "ì´ìœ : í…ìŠ¤íŠ¸ì—ì„œëŠ” ì œí’ˆì˜ í’ˆì§ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì¹˜ê³ , ê°€ê²© ëŒ€ë¹„ ì•„ì‰¬ìš´ ì ì´ ë§ë‹¤ëŠ” ë‚´ìš©ì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì œí’ˆì— ëŒ€í•œ ì‹¤ë§ê³¼ ì•„ì‰¬ì›€ì„ í‘œí˜„í•œ ê²ƒìœ¼ë¡œ ë¶€ì •ì ì¸ ê°ì •ì„ ë‚˜íƒ€ë‚´ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "â±ï¸ ì‘ë‹µ ì‹œê°„: 1.85ì´ˆ\n",
      "ğŸ“Š í† í° ì‚¬ìš©: 233\n"
     ]
    }
   ],
   "source": [
    "# ê°™ì€ ì§ˆë¬¸ìœ¼ë¡œ ëª¨ë¸ ë¹„êµ\n",
    "prompt = \"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ê¸ì •/ë¶€ì •/ì¤‘ë¦½ìœ¼ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\n",
    "ê·¸ë¦¬ê³  ê·¸ë ‡ê²Œ íŒë‹¨í•œ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: \"ì œí’ˆ ë°°ì†¡ì€ ë¹¨ëì§€ë§Œ, í’ˆì§ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì³¤ìŠµë‹ˆë‹¤. ê°€ê²© ëŒ€ë¹„ ì•„ì‰¬ìš´ ì ì´ ë§ë„¤ìš”.\"\n",
    "\"\"\"\n",
    "\n",
    "models = [\"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"]\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ëª¨ë¸: {model}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "    print(f\"\\nâ±ï¸ ì‘ë‹µ ì‹œê°„: {elapsed:.2f}ì´ˆ\")\n",
    "    print(f\"ğŸ“Š í† í° ì‚¬ìš©: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "json-mode",
   "metadata": {},
   "source": [
    "### JSON ëª¨ë“œ - êµ¬ì¡°í™”ëœ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "json-mode-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì¶œëœ ì •ë³´:\n",
      "{\n",
      "  \"name\": \"í™ê¸¸ë™\",\n",
      "  \"age\": 30,\n",
      "  \"gender\": \"ë‚¨ì„±\",\n",
      "  \"city\": \"ì„œìš¸\",\n",
      "  \"job\": \"ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´\",\n",
      "  \"hobbies\": [\n",
      "    \"ë…ì„œ\",\n",
      "    \"ë“±ì‚°\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ ë°›ê¸°\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"ë‹¹ì‹ ì€ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:\n",
    "            \n",
    "            \"í™ê¸¸ë™ì€ 30ì„¸ ë‚¨ì„±ì´ë©°, ì„œìš¸ì— ê±°ì£¼í•©ë‹ˆë‹¤. ì§ì—…ì€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì´ê³ , \n",
    "            ì·¨ë¯¸ëŠ” ë…ì„œì™€ ë“±ì‚°ì…ë‹ˆë‹¤.\"\n",
    "            \n",
    "            JSON í˜•ì‹: {\"name\": str, \"age\": int, \"gender\": str, \"city\": str, \n",
    "                        \"job\": str, \"hobbies\": list}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},  # JSON ëª¨ë“œ í™œì„±í™”\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "result = json.loads(response.choices[0].message.content)\n",
    "print(\"ì¶”ì¶œëœ ì •ë³´:\")\n",
    "print(json.dumps(result, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "project-header",
   "metadata": {},
   "source": [
    "## 8. ë¯¸ë‹ˆ í”„ë¡œì íŠ¸: ê°„ë‹¨í•œ ì±—ë´‡ ë§Œë“¤ê¸°\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ Streamlitì„ í™œìš©í•œ ì‹¤ìš©ì ì¸ ì±—ë´‡ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤!  \n",
    "\n",
    "`Streamlit`ì€ ì¥¬í”¼í„° ë…¸íŠ¸ë¶ì—ì„œëŠ” ì‹¤í–‰ì´ ë¶ˆê°€ëŠ¥í•´ì„œ, `streamlit_chatgpt.py` í˜•íƒœë¡œ ì½”ë“œë¥¼ ë’€ìŠµë‹ˆë‹¤.  \n",
    "ê°ì í„°ë¯¸ë„ì„ ì—´ê³  ì•„ë˜ì²˜ëŸ¼ ì‹¤í–‰í•´ë³´ì„¸ìš”:\n",
    "\n",
    "```\n",
    "cd ~/metacode-202014/01.ChatGPT-API\n",
    "streamlit run streamlit_chatgpt.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e82c1-f2c3-4640-b71f-ca509852abc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
